

from collections import UserDict, UserList
import csv
from dataclasses import asdict
import functools
import json
import logging
from pathlib import Path
import sys
from typing import Any, Dict, Generator, Iterable, List, Optional, Tuple, Union
sys.path += [str(Path(__file__).parent.parent)]

from ioTypes.combination import Combination
from ioTypes.pelmo import PECResult
from util.conversions import EnhancedJSONEncoder
from pelmo.runner import PelmoResult
from ioTypes.compound import Compound
from ioTypes.gap import GAP

def rebuild_scatterd_to_file(file: Path, parent: Path, output_format: Optional[str] = None, glob_pattern: str = "output.json", psm_root = Path.cwd()):
    write_results_to_file(rebuild_scattered_output(parent, glob_pattern, psm_root), file, output_format)

def rebuild_output_to_file(file: Path, source: Union[Path, List[PelmoResult]], output_format: Optional[str], psm_root = Path.cwd()):
    write_results_to_file(rebuild_output(source, psm_root), file, output_format)

def write_results_to_file(results: Iterable[PECResult], file: Path, format: Optional[str] = None):
    if format == None:
        format = file.suffix[1:]
    if format == 'json':
        with file.with_suffix('.json').open('w') as fp:
            results = list(results)
            json.dump(results, fp, cls=EnhancedJSONEncoder)
    elif format == 'csv':
        with file.with_suffix('.csv').open('w', newline='') as fp:
            writer = csv.writer(fp,)
            doubles = list(flatten_to_tuples(next(results)._asdict()))
            header = [x[0] for x in doubles]
            row = [x[1] for x in doubles]
            writer.writerow(header)
            writer.writerow(row)
            writer.writerows((x[1] for x in flatten_to_tuples(r._asdict())) for r in results)
    else:
        raise ValueError("Could not infer format, please specify explicitly")

def flatten_to_tuples(o: Any, prefix: List[str] = []) -> Generator[Tuple[str, str], None, None]:
    if isinstance(o, (dict, UserDict)):
        yield from flatten_dict_to_tuples(o, prefix)
    elif isinstance(o, (list, UserList)):
        yield from flatten_list_to_tuples(o, prefix)
    elif isinstance(o, Compound):
        for key, value in flatten_to_tuples(asdict(o), prefix):
            yield key, value
    else:
        yield ".".join(prefix), str(o)

def flatten_dict_to_tuples(d: Dict, prefix: List[str] = []) -> Generator[Tuple[str, str], None, None]:
    sys.stdout.flush()
    for key, value in d.items():
        for k, v in flatten_to_tuples(value, prefix=prefix + [str(key)]):
            yield k, v
        
def flatten_list_to_tuples(l: List, prefix: List[str] = []) -> Generator[Tuple[str, str], None, None]:
    for index, value in enumerate(l):
        for k, v in flatten_to_tuples(value, prefix=prefix + [str(index)]):
            yield k, v

def rebuild_scattered_output(parent: Path, glob_pattern: str = "output.json", psm_root = Path.cwd()) -> Generator[PECResult, None, None]:
    logger = logging.getLogger()
    logger.debug("Iterating over output files %s", list(parent.rglob(glob_pattern)))
    for file in parent.rglob(glob_pattern):
        for output in rebuild_output(file, psm_root):
            yield output

def rebuild_output(source: Union[Path, List[PelmoResult]], psm_root = Path.cwd()) -> Generator[PECResult, None, None]:
    logger = logging.getLogger()
    if isinstance(source, Path):
        with source.open() as fp:
            outputs = json.load(fp)
        outputs = [PelmoResult(**item) for item in outputs]
    else:
        outputs = source 
    for output in outputs:
        psm_file = psm_root / output.psm
        with psm_file.open() as psm:
            psm.readline()
            input_data_locations = json.loads(psm.readline())
        if 'compound' in input_data_locations.keys() and 'gap' in input_data_locations.keys():
            compound_file = Path(input_data_locations['compound'])
            gap_file = Path(input_data_locations['gap'])
            logger.debug({"compound_file": compound_file, "gap_file": gap_file})
            compound = get_compound(compound_file)
            gap = get_gap(gap_file)
        elif 'combination' in input_data_locations.keys():
            combination_file = Path(input_data_locations['combination'])
            with combination_file.open() as fp:
                combination = Combination(**json.loads(fp))
            compound = combination.compound
            gap = combination.gap
        else:
            raise ValueError('Could not find origin input data for psm file. Is the comment set to the metadata generated by creator.py?')
        yield PECResult(compound=compound, gap=gap, crop=output.crop, scenario=output.scenario, pec=output.pec)

@functools.lru_cache(maxsize=None)
def get_compound(file: Path) -> Compound:
    with file.open() as fp:
        content = json.load(fp)
    return Compound(**content)

@functools.lru_cache(maxsize=None)
def get_gap(file: Path) -> GAP:
    with file.open() as fp:
        content = json.load(fp)
    return GAP(**content)
